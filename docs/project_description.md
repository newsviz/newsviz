# Как всё работает
Вся база проекта лежит в директории NewsViz прямо в корне. Там же есть поддиректории под дополнительные части, которые вполне заменяемы.  

Главные приключения происходят в скрипте `pipeline.py`. В нём объявлен luigi-pipeline который выполняет главные этапы работы с данными. Подробнее про luigi можно почитать в [его документации](https://luigi.readthedocs.io/en/stable/). В двух словах, луиджи -- это фреймворк для построение пайплайнов обработки данных. Суть в том, что каждый этап может иметь зависимости от других этапов. Если запустить этап с зависимостями, то луиджи проверит, были ли выполнены предыдущие шаги, и выполнит их, если необходимо.

## Как работает luigi
Для работы необходимо понимать только, что каждый таск -- это класс унаследованный от `luigi.Task`. Он имеет метод `run` в котором выполняется вся полезная работа. Метод `output` должен описывать как выглядит результат. То есть, например пути к файлам, которые появятся в результате работы метода `run`. Метод `requires` должен показывать какие другие таски должны быть выполнены прежде, чем выполнять текущую. Луиджи будет вызывать у каждой из зависимостей метод `output` и проверять, существует ли описанный результат. Там можно прокидывать параметры. У нас просто прокидывается путь к файлу конфигурации из этапа в этап. Например, этап классификации просто передаёт этапу предобработки свой параметр `conf`:  
```
def requires(self):

return PreprocessorTask(conf=self.conf)
```

## Итак, что же у нас в пайплайне:
`PreprocessorTask`  
Собирает всё, что лежит в директории с сырыми данными, делает лемматизацию, удаление стоп-слов и токенизацию и складывает в директорию для обработанных данных. Путь к директории с сырыми данными и с обработанными задаётся файлом конфигурации, а путь к файлу конфигурации задаётся аргументом при запуске.

**TODO: описать входной и выходной формат данных и директорий**

`RubricClassifierTask`  
Берёт данные из директории для обработанных данных, берёт предобученную модель, и извлекалку признаков и применяет модель к данным. Складывает всё в директорию для классифицированных данных, которая тоже задаётся конфигом.

**TODO: описать входной и выходной формат данных и директорий**

`TopicPredictorTask`  
Берёт классифицированные данные, берёт предобученную модель bigARTM и применяет её к классифицированным данным. На выходе получаем для каждого документа вектор тем.

**TODO: описать входной и выходной формат данных и директорий**

## Общие вещи
Мы работаем со схемой "по директории на источник". И этот набор директорий дублируется между этапами. Это позволяет при добавлении новых данных не пересчитывать всё с нуля. Мы не используем базы данных, потому что хотим сохранить в первую очередь простоту разработки и поддержки и не тащить слишком много зависимостей.
